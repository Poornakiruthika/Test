{
  "_args": [
    [
      {
        "raw": "broken-link-checker",
        "scope": null,
        "escapedName": "broken-link-checker",
        "name": "broken-link-checker",
        "rawSpec": "",
        "spec": "latest",
        "type": "tag"
      },
      "D:\\dev\\nightwatch\\node_modules\\nightwatch"
    ]
  ],
  "_from": "broken-link-checker@latest",
  "_id": "broken-link-checker@0.7.5",
  "_inCache": true,
  "_location": "/broken-link-checker",
  "_nodeVersion": "7.10.0",
  "_npmOperationalInternal": {
    "host": "packages-12-west.internal.npmjs.com",
    "tmp": "tmp/broken-link-checker-0.7.5.tgz_1494889714044_0.21529205911792815"
  },
  "_npmUser": {
    "name": "stevenvachon",
    "email": "contact@svachon.com"
  },
  "_npmVersion": "4.2.0",
  "_phantomChildren": {
    "escape-string-regexp": "1.0.5"
  },
  "_requested": {
    "raw": "broken-link-checker",
    "scope": null,
    "escapedName": "broken-link-checker",
    "name": "broken-link-checker",
    "rawSpec": "",
    "spec": "latest",
    "type": "tag"
  },
  "_requiredBy": [
    "#USER"
  ],
  "_resolved": "https://registry.npmjs.org/broken-link-checker/-/broken-link-checker-0.7.5.tgz",
  "_shasum": "ed9f89a3d358b25377d6098b91cf0ffed41be6cf",
  "_shrinkwrap": null,
  "_spec": "broken-link-checker",
  "_where": "D:\\dev\\nightwatch\\node_modules\\nightwatch",
  "author": {
    "name": "Steven Vachon",
    "email": "contact@svachon.com",
    "url": "http://www.svachon.com/"
  },
  "bin": {
    "blc": "bin/blc",
    "broken-link-checker": "bin/blc"
  },
  "bugs": {
    "url": "https://github.com/stevenvachon/broken-link-checker/issues"
  },
  "dependencies": {
    "bhttp": "^1.2.1",
    "calmcard": "~0.1.1",
    "chalk": "^1.1.3",
    "char-spinner": "^1.0.1",
    "condense-whitespace": "^1.0.0",
    "default-user-agent": "^1.0.0",
    "errno": "~0.1.4",
    "extend": "^3.0.0",
    "http-equiv-refresh": "^1.0.0",
    "humanize-duration": "^3.9.1",
    "is-stream": "^1.0.1",
    "is-string": "^1.0.4",
    "limited-request-queue": "^2.0.0",
    "link-types": "^1.1.0",
    "maybe-callback": "^2.1.0",
    "nopter": "~0.3.0",
    "parse5": "^3.0.2",
    "robot-directives": "~0.3.0",
    "robots-txt-guard": "~0.1.0",
    "robots-txt-parse": "~0.0.4",
    "urlcache": "~0.6.0",
    "urlobj": "0.0.10"
  },
  "description": "Find broken links, missing images, etc in your HTML.",
  "devDependencies": {
    "chai": "^3.5.0",
    "chai-as-promised": "^6.0.0",
    "chai-like": "~0.2.10",
    "chai-things": "~0.2.0",
    "es6-promise": "^4.1.0",
    "mocha": "^3.0.2",
    "object.assign": "^4.0.4",
    "slashes": "^1.0.5",
    "st": "^1.2.0"
  },
  "directories": {},
  "dist": {
    "shasum": "ed9f89a3d358b25377d6098b91cf0ffed41be6cf",
    "tarball": "https://registry.npmjs.org/broken-link-checker/-/broken-link-checker-0.7.5.tgz"
  },
  "engines": {
    "node": ">= 0.10"
  },
  "files": [
    "bin",
    "lib"
  ],
  "gitHead": "6ddccb1b7ead9149b040a18836ef6476c5d896e6",
  "homepage": "https://github.com/stevenvachon/broken-link-checker",
  "keywords": [
    "404",
    "html",
    "hyperlink",
    "links",
    "seo",
    "url"
  ],
  "license": "MIT",
  "main": "lib",
  "maintainers": [
    {
      "name": "stevenvachon",
      "email": "contact@svachon.com"
    }
  ],
  "name": "broken-link-checker",
  "optionalDependencies": {},
  "readme": "# broken-link-checker [![NPM Version][npm-image]][npm-url] [![Build Status][travis-image]][travis-url] [![Dependency Status][david-image]][david-url]\n\n> Find broken links, missing images, etc in your HTML.\n\nFeatures:\n* Stream-parses local and remote HTML pages\n* Concurrently checks multiple links\n* Supports various HTML elements/attributes, not just `<a href>`\n* Supports redirects, absolute URLs, relative URLs and `<base>`\n* Honors robot exclusions\n* Provides detailed information about each link (HTTP and HTML)\n* URL keyword filtering with wildcards\n* Pause/Resume at any time\n\n\n## Installation\n\n[Node.js](http://nodejs.org/) `>= 0.10` is required; `< 4.0` will need `Promise` and `Object.assign` polyfills.\n\nThere're two ways to use it:\n\n### Command Line Usage\nTo install, type this at the command line:\n```shell\nnpm install broken-link-checker -g\n```\nAfter that, check out the help for available options:\n```shell\nblc --help\n```\nA typical site-wide check might look like:\n```shell\nblc http://yoursite.com -ro\n```\n\n### Programmatic API\nTo install, type this at the command line:\n```shell\nnpm install broken-link-checker\n```\nThe rest of this document will assist you with how to use the API.\n\n\n## Classes\n\n### `blc.HtmlChecker(options, handlers)`\nScans an HTML document to find broken links.\n\n* `handlers.complete` is fired after the last result or zero results.\n* `handlers.html` is fired after the HTML document has been fully parsed.\n  * `tree` is supplied by [parse5](https://npmjs.com/parse5)\n  * `robots` is an instance of [robot-directives](https://npmjs.com/robot-directives) containing any `<meta>` robot exclusions.\n* `handlers.junk` is fired with data on each skipped link, as configured in options.\n* `handlers.link` is fired with the result of each discovered link (broken or not).\n\n* `.clearCache()` will remove any cached URL responses. This is only relevant if the `cacheResponses` option is enabled.\n* `.numActiveLinks()` returns the number of links with active requests.\n* `.numQueuedLinks()` returns the number of links that currently have no active requests.\n* `.pause()` will pause the internal link queue, but will not pause any active requests.\n* `.resume()` will resume the internal link queue.\n* `.scan(html, baseUrl)` parses & scans a single HTML document. Returns `false` when there is a previously incomplete scan (and `true` otherwise).\n  * `html` can be a stream or a string.\n  * `baseUrl` is the address to which all relative URLs will be made absolute. Without a value, links to relative URLs will output an \"Invalid URL\" error.\n\n```js\nvar htmlChecker = new blc.HtmlChecker(options, {\n\thtml: function(tree, robots){},\n\tjunk: function(result){},\n\tlink: function(result){},\n\tcomplete: function(){}\n});\n\nhtmlChecker.scan(html, baseUrl);\n```\n\n### `blc.HtmlUrlChecker(options, handlers)`\nScans the HTML content at each queued URL to find broken links.\n\n* `handlers.end` is fired when the end of the queue has been reached.\n* `handlers.html` is fired after a page's HTML document has been fully parsed.\n  * `tree` is supplied by [parse5](https://npmjs.com/parse5).\n  * `robots` is an instance of [robot-directives](https://npmjs.com/robot-directives) containing any `<meta>` and `X-Robots-Tag` robot exclusions.\n* `handlers.junk` is fired with data on each skipped link, as configured in options.\n* `handlers.link` is fired with the result of each discovered link (broken or not) within the current page.\n* `handlers.page` is fired after a page's last result, on zero results, or if the HTML could not be retrieved.\n\n* `.clearCache()` will remove any cached URL responses. This is only relevant if the `cacheResponses` option is enabled.\n* `.dequeue(id)` removes a page from the queue. Returns `true` on success or an `Error` on failure.\n* `.enqueue(pageUrl, customData)` adds a page to the queue. Queue items are auto-dequeued when their requests are complete. Returns a queue ID on success or an `Error` on failure.\n  * `customData` is optional data that is stored in the queue item for the page.\n* `.numActiveLinks()` returns the number of links with active requests.\n* `.numPages()` returns the total number of pages in the queue.\n* `.numQueuedLinks()` returns the number of links that currently have no active requests.\n* `.pause()` will pause the queue, but will not pause any active requests.\n* `.resume()` will resume the queue.\n\n```js\nvar htmlUrlChecker = new blc.HtmlUrlChecker(options, {\n\thtml: function(tree, robots, response, pageUrl, customData){},\n\tjunk: function(result, customData){},\n\tlink: function(result, customData){},\n\tpage: function(error, pageUrl, customData){},\n\tend: function(){}\n});\n\nhtmlUrlChecker.enqueue(pageUrl, customData);\n```\n\n### `blc.SiteChecker(options, handlers)`\nRecursively scans (crawls) the HTML content at each queued URL to find broken links.\n\n* `handlers.end` is fired when the end of the queue has been reached.\n* `handlers.html` is fired after a page's HTML document has been fully parsed.\n  * `tree` is supplied by [parse5](https://npmjs.com/parse5).\n  * `robots` is an instance of [robot-directives](https://npmjs.com/robot-directives) containing any `<meta>` and `X-Robots-Tag` robot exclusions.\n* `handlers.junk` is fired with data on each skipped link, as configured in options.\n* `handlers.link` is fired with the result of each discovered link (broken or not) within the current page.\n* `handlers.page` is fired after a page's last result, on zero results, or if the HTML could not be retrieved.\n* `handlers.robots` is fired after a site's robots.txt has been downloaded and provides an instance of [robots-txt-guard](https://npmjs.com/robots-txt-guard).\n* `handlers.site` is fired after a site's last result, on zero results, or if the *initial* HTML could not be retrieved.\n\n* `.clearCache()` will remove any cached URL responses. This is only relevant if the `cacheResponses` option is enabled.\n* `.dequeue(id)` removes a site from the queue. Returns `true` on success or an `Error` on failure.\n* `.enqueue(siteUrl, customData)` adds [the first page of] a site to the queue. Queue items are auto-dequeued when their requests are complete. Returns a queue ID on success or an `Error` on failure.\n  * `customData` is optional data that is stored in the queue item for the site.\n* `.numActiveLinks()` returns the number of links with active requests.\n* `.numPages()` returns the total number of pages in the queue.\n* `.numQueuedLinks()` returns the number of links that currently have no active requests.\n* `.numSites()` returns the total number of sites in the queue.\n* `.pause()` will pause the queue, but will not pause any active requests.\n* `.resume()` will resume the queue.\n\n**Note:** `options.filterLevel` is used for determining which links are recursive.\n\n```js\nvar siteChecker = new blc.SiteChecker(options, {\n\trobots: function(robots, customData){},\n\thtml: function(tree, robots, response, pageUrl, customData){},\n\tjunk: function(result, customData){},\n\tlink: function(result, customData){},\n\tpage: function(error, pageUrl, customData){},\n\tsite: function(error, siteUrl, customData){},\n\tend: function(){}\n});\n\nsiteChecker.enqueue(siteUrl, customData);\n```\n\n### `blc.UrlChecker(options, handlers)`\nRequests each queued URL to determine if they are broken.\n\n* `handlers.end` is fired when the end of the queue has been reached.\n* `handlers.link` is fired for each result (broken or not).\n\n* `.clearCache()` will remove any cached URL responses. This is only relevant if the `cacheResponses` option is enabled.\n* `.dequeue(id)` removes a URL from the queue. Returns `true` on success or an `Error` on failure.\n* `.enqueue(url, baseUrl, customData)` adds a URL to the queue. Queue items are auto-dequeued when their requests are completed. Returns a queue ID on success or an `Error` on failure.\n  * `baseUrl` is the address to which all relative URLs will be made absolute. Without a value, links to relative URLs will output an \"Invalid URL\" error.\n  * `customData` is optional data that is stored in the queue item for the URL.\n* `.numActiveLinks()` returns the number of links with active requests.\n* `.numQueuedLinks()` returns the number of links that currently have no active requests.\n* `.pause()` will pause the queue, but will not pause any active requests.\n* `.resume()` will resume the queue.\n\n```js\nvar urlChecker = new blc.UrlChecker(options, {\n\tlink: function(result, customData){},\n\tend: function(){}\n});\n\nurlChecker.enqueue(url, baseUrl, customData);\n```\n\n## Options\n\n### `options.acceptedSchemes`\nType: `Array`  \nDefault value: `[\"http\",\"https\"]`  \nWill only check links with schemes/protocols mentioned in this list. Any others (except those in `excludedSchemes`) will output an \"Invalid URL\" error.\n\n### `options.cacheExpiryTime`\nType: `Number`  \nDefault Value: `3600000` (1 hour)  \nThe number of milliseconds in which a cached response should be considered valid. This is only relevant if the `cacheResponses` option is enabled.\n\n### `options.cacheResponses`\nType: `Boolean`  \nDefault Value: `true`  \nURL request results will be cached when `true`. This will ensure that each unique URL will only be checked once.\n\n### `options.excludedKeywords`\nType: `Array`  \nDefault value: `[]`  \nWill not check or output links that match the keywords and glob patterns in this list. The only wildcard supported is `*`.\n\nThis option does *not* apply to `UrlChecker`.\n\n### `options.excludedSchemes`\nType: `Array`  \nDefault value: `[\"data\",\"geo\",\"javascript\",\"mailto\",\"sms\",\"tel\"]`  \nWill not check or output links with schemes/protocols mentioned in this list. This avoids the output of \"Invalid URL\" errors with links that cannot be checked.\n\nThis option does *not* apply to `UrlChecker`.\n\n### `options.excludeExternalLinks`\nType: `Boolean`  \nDefault value: `false`  \nWill not check or output external links when `true`; relative links with a remote `<base>` included.\n\nThis option does *not* apply to `UrlChecker`.\n\n### `options.excludeInternalLinks`\nType: `Boolean`  \nDefault value: `false`  \nWill not check or output internal links when `true`.\n\nThis option does *not* apply to `UrlChecker` nor `SiteChecker`'s *crawler*.\n\n### `options.excludeLinksToSamePage`\nType: `Boolean`  \nDefault value: `true`  \nWill not check or output links to the same page; relative and absolute fragments/hashes included.\n\nThis option does *not* apply to `UrlChecker`.\n\n### `options.filterLevel`\nType: `Number`  \nDefault value: `1`  \nThe tags and attributes that are considered links for checking, split into the following levels:\n* `0`: clickable links\n* `1`: clickable links, media, iframes, meta refreshes\n* `2`: clickable links, media, iframes, meta refreshes, stylesheets, scripts, forms\n* `3`: clickable links, media, iframes, meta refreshes, stylesheets, scripts, forms, metadata\n\nRecursive links have a slightly different filter subset. To see the exact breakdown of both, check out the [tag map](https://github.com/stevenvachon/broken-link-checker/blob/master/lib/internal/tags.js). `<base>` is not listed because it is not a link, though it is always parsed.\n\nThis option does *not* apply to `UrlChecker`.\n\n### `options.honorRobotExclusions`\nType: `Boolean`  \nDefault value: `true`  \nWill not scan pages that search engine crawlers would not follow. Such will have been specified with any of the following:\n* `<a rel=\"nofollow\" href=\"…\">`\n* `<area rel=\"nofollow\" href=\"…\">`\n* `<meta name=\"robots\" content=\"noindex,nofollow,…\">`\n* `<meta name=\"googlebot\" content=\"noindex,nofollow,…\">`\n* `<meta name=\"robots\" content=\"unavailable_after: …\">`\n* `X-Robots-Tag: noindex,nofollow,…`\n* `X-Robots-Tag: googlebot: noindex,nofollow,…`\n* `X-Robots-Tag: otherbot: noindex,nofollow,…`\n* `X-Robots-Tag: unavailable_after: …`\n* robots.txt\n\nThis option does *not* apply to `UrlChecker`.\n\n### `options.maxSockets`\nType: `Number`  \nDefault value: `Infinity`  \nThe maximum number of links to check at any given time.\n\n### `options.maxSocketsPerHost`\nType: `Number`  \nDefault value: `1`  \nThe maximum number of links per host/port to check at any given time. This avoids overloading a single target host with too many concurrent requests. This will not limit concurrent requests to other hosts.\n\n### `options.rateLimit`\nType: `Number`  \nDefault value: `0`  \nThe number of milliseconds to wait before each request.\n\n### `options.requestMethod`\nType: `String`  \nDefault value: `\"head\"`  \nThe HTTP request method used in checking links. If you experience problems, try using `\"get\"`, however `options.retry405Head` should have you covered.\n\n### `options.retry405Head`\nType: `Boolean`  \nDefault value: `true`  \nSome servers do not respond correctly to a `\"head\"` request method. When `true`, a link resulting in an HTTP 405 \"Method Not Allowed\" error will be re-requested using a `\"get\"` method before deciding that it is broken.\n\n### `options.userAgent`\nType: `String`  \nDefault value: `\"broken-link-checker/0.7.0 Node.js/5.5.0 (OS X El Capitan; x64)\"` (or similar)  \nThe HTTP user-agent to use when checking links as well as retrieving pages and robot exclusions.\n\n\n## Handling Broken/Excluded Links\nA broken link will have a `broken` value of `true` and a reason code defined in `brokenReason`. A link that was not checked (emitted as `\"junk\"`) will have an `excluded` value of `true` and a reason code defined in `excludedReason`.\n```js\nif (result.broken) {\n\tconsole.log(result.brokenReason);\n\t//=> HTTP_404\n} else if (result.excluded) {\n\tconsole.log(result.excludedReason);\n\t//=> BLC_ROBOTS\n}\n```\n\nAdditionally, more descriptive messages are available for each reason code:\n```js\nconsole.log(blc.BLC_ROBOTS);       //=> Robots Exclusion\nconsole.log(blc.ERRNO_ECONNRESET); //=> connection reset by peer (ECONNRESET)\nconsole.log(blc.HTTP_404);         //=> Not Found (404)\n\n// List all\nconsole.log(blc);\n```\n\nPutting it all together:\n```js\nif (result.broken) {\n\tconsole.log(blc[result.brokenReason]);\n} else if (result.excluded) {\n\tconsole.log(blc[result.excludedReason]);\n}\n```\n\n## HTML and HTTP information\nDetailed information for each link result is provided. Check out the [schema](https://github.com/stevenvachon/broken-link-checker/blob/master/lib/internal/linkObj.js#L16-L64) or:\n```js\nconsole.log(result);\n```\n\n\n## Roadmap Features\n* fix issue where same-page links are not excluded when cache is enabled, despite `excludeLinksToSamePage===true`\n* publicize filter handlers\n* add cheerio support by using parse5's htmlparser2 tree adaptor?\n* add `rejectUnauthorized:false` option to avoid `UNABLE_TO_VERIFY_LEAF_SIGNATURE`\n* load sitemap.xml at end of each `SiteChecker` site to possibly check pages that were not linked to\n* remove `options.excludedSchemes` and handle schemes not in `options.acceptedSchemes` as junk?\n* change order of checking to: tcp error, 4xx code (broken), 5xx code (undetermined), 200\n* abort download of body when `options.retry405Head===true`\n* option to retry broken links a number of times (default=0)\n* option to scrape `response.body` for erroneous sounding text (using [fathom](https://npmjs.com/fathom-web)?), since an error page could be presented but still have code 200\n* option to check broken link on archive.org for archived version (using [this lib](https://npmjs.com/archive.org))\n* option to run `HtmlUrlChecker` checks on page load (using [jsdom](https://npmjs.com/jsdom)) to include links added with JavaScript?\n* option to check if hashes exist in target URL document?\n* option to parse Markdown in `HtmlChecker` for links\n* option to play sound when broken link is found\n* option to hide unbroken links\n* option to check plain text URLs\n* add throttle profiles (0–9, -1 for \"custom\") for easy configuring\n* check [ftp:](https://nmjs.com/ftp), [sftp:](https://npmjs.com/ssh2) (for downloadable files)\n* check ~~mailto:~~, news:, nntp:, telnet:?\n* check local files if URL is relative and has no base URL?\n* cli json mode -- streamed or not?\n* cli non-tty mode -- change nesting ASCII artwork to time stamps?\n\n\n[npm-image]: https://img.shields.io/npm/v/broken-link-checker.svg\n[npm-url]: https://npmjs.org/package/broken-link-checker\n[travis-image]: https://img.shields.io/travis/stevenvachon/broken-link-checker.svg\n[travis-url]: https://travis-ci.org/stevenvachon/broken-link-checker\n[david-image]: https://img.shields.io/david/stevenvachon/broken-link-checker.svg\n[david-url]: https://david-dm.org/stevenvachon/broken-link-checker\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git://github.com/stevenvachon/broken-link-checker.git"
  },
  "scripts": {
    "test": "mocha test/ --reporter spec --check-leaks --bail",
    "test-watch": "mocha test/ --reporter spec --check-leaks --bail -w"
  },
  "version": "0.7.5"
}
