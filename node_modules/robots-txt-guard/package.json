{
  "_args": [
    [
      {
        "raw": "robots-txt-guard@~0.1.0",
        "scope": null,
        "escapedName": "robots-txt-guard",
        "name": "robots-txt-guard",
        "rawSpec": "~0.1.0",
        "spec": ">=0.1.0 <0.2.0",
        "type": "range"
      },
      "D:\\dev\\nightwatch\\node_modules\\nightwatch\\node_modules\\broken-link-checker"
    ]
  ],
  "_from": "robots-txt-guard@>=0.1.0 <0.2.0",
  "_id": "robots-txt-guard@0.1.0",
  "_inCache": true,
  "_location": "/robots-txt-guard",
  "_npmUser": {
    "name": "janpotoms",
    "email": "potoms.jan@gmail.com"
  },
  "_npmVersion": "1.4.28",
  "_phantomChildren": {},
  "_requested": {
    "raw": "robots-txt-guard@~0.1.0",
    "scope": null,
    "escapedName": "robots-txt-guard",
    "name": "robots-txt-guard",
    "rawSpec": "~0.1.0",
    "spec": ">=0.1.0 <0.2.0",
    "type": "range"
  },
  "_requiredBy": [
    "/broken-link-checker"
  ],
  "_resolved": "https://registry.npmjs.org/robots-txt-guard/-/robots-txt-guard-0.1.0.tgz",
  "_shasum": "2fd5ec85cbeb4690431e9bbb5c84542f882859e8",
  "_shrinkwrap": null,
  "_spec": "robots-txt-guard@~0.1.0",
  "_where": "D:\\dev\\nightwatch\\node_modules\\nightwatch\\node_modules\\broken-link-checker",
  "author": {
    "name": "Jan Potoms"
  },
  "dependencies": {},
  "description": "Validate urls against robots.txt rules.",
  "devDependencies": {
    "chai": "^1.9.1",
    "mocha": "^2.0.1"
  },
  "directories": {},
  "dist": {
    "shasum": "2fd5ec85cbeb4690431e9bbb5c84542f882859e8",
    "tarball": "https://registry.npmjs.org/robots-txt-guard/-/robots-txt-guard-0.1.0.tgz"
  },
  "gitHead": "2bc24c10d040675eb28fefb8217fbb805a24a5ea",
  "license": "MIT",
  "main": "lib/guard.js",
  "maintainers": [
    {
      "name": "janpotoms",
      "email": "potoms.jan@gmail.com"
    }
  ],
  "name": "robots-txt-guard",
  "optionalDependencies": {},
  "readme": "# robots-txt-guard\n\nValidate urls against robots.txt rules. Configure with output from [robots-txt-parse](https://github.com/Woorank/robots-txt-parse/)\n\n## Usage\n\n```js\nvar guard = require('robots-txt-guard');\n\nvar robotsTxt = guard({\n  groups: [{\n    agents: [ '*' ],\n    rules: [\n      { rule: 'allow', path: '/' }\n    ]\n  }, {\n    agents: [ 'googlebot', 'twitterbot' ],\n    rules: [\n      { rule: 'disallow', path: '/tmp/*' },\n      { rule: 'disallow', path: '/temporary/*' }\n    ]\n  }]\n});\n\nrobotsTxt.isAllowed('Googlebot', '/tmp/abc'); // false\nrobotsTxt.isAllowed('mozilla', '/tmp/abc'); // true\nrobotsTxt.isAllowed('googlebot-news', '/home.html'); // true\n```\n",
  "readmeFilename": "README.md",
  "scripts": {
    "test": "mocha -R spec ./test",
    "test-watch": "mocha -w -R spec ./test"
  },
  "version": "0.1.0"
}
